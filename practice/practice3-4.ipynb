{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "practice3-4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jS0ZVOWBSVRy"
      },
      "source": [
        "## 練習題 3-4\n",
        "\n",
        "請協助調整以下API 程式碼，讓使用者可以調用該API 服務輸入資料，並透過該API 服務進行預測\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGSo7X1YfNRS",
        "cellView": "form"
      },
      "source": [
        "#@markdown 安裝Tensorflow Serving \n",
        "! echo \"deb [arch=amd64] http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\" | sudo tee /etc/apt/sources.list.d/tensorflow-serving.list && \\\n",
        "curl https://storage.googleapis.com/tensorflow-serving-apt/tensorflow-serving.release.pub.gpg | sudo apt-key add -\n",
        "! apt-get update && apt-get install tensorflow-model-server > /dev/null\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyyeNEmzfN4E",
        "cellView": "form"
      },
      "source": [
        "#@markdown 解壓縮 sample_model\n",
        "\n",
        "! wget https://raw.githubusercontent.com/ywchiu/HPPY/main/model/sample_model.zip > /dev/null\n",
        "! wget https://raw.githubusercontent.com/ywchiu/HPPY/main/model/encoder.pickle > /dev/null\n",
        "! unzip sample_model.zip > /dev/null\n",
        "! ls sample_model/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixfpSlsvcRYW"
      },
      "source": [
        "### 預測類別 Sentiment_prediciton"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10odm4i3a0Ll"
      },
      "source": [
        "import tensorflow as tf\n",
        "from  tensorflow.keras.models import load_model\n",
        "import pickle\n",
        "\n",
        "class Sentiment_prediciton(object):\n",
        "  def __init__(self, model_name, encoder_name):\n",
        "    self.model = load_model(model_name)\n",
        "    with open(encoder_name, 'rb') as handle:\n",
        "      self.encoder = pickle.load(handle)\n",
        "\n",
        "  def pad_to_size(self, vec, size):\n",
        "    zeros = [0] * (size - len(vec))\n",
        "    vec.extend(zeros)\n",
        "    return vec\n",
        "\n",
        "  def sample_predict(self, sample_pred_text, pad):\n",
        "    encoded_sample_pred_text = self.encoder.encode(sample_pred_text)\n",
        "\n",
        "    if pad:\n",
        "      encoded_sample_pred_text = pad_to_size(encoded_sample_pred_text, 64)\n",
        "    encoded_sample_pred_text = tf.cast(encoded_sample_pred_text, tf.float32)\n",
        "    predictions = self.model.predict(tf.expand_dims(encoded_sample_pred_text, 0))\n",
        "\n",
        "    return (predictions)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9KAGlUMZGxQ",
        "outputId": "b7511687-4498-41f2-eed8-2a8fbb4f92a6"
      },
      "source": [
        "predictor = Sentiment_prediciton('sample_model', 'encoder.pickle')\n",
        "predictions = predictor.sample_predict(('this is the worst movie I have ever had'), pad=False)\n",
        "print(predictions)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-1.8166885]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GT8HrzTpgoDp"
      },
      "source": [
        "### 請完成以下程式碼，讓使用者得以用 Flask 提供正負向情緒判斷服務"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SB_lGOOaf4gU"
      },
      "source": [
        "from  tensorflow.keras.models import load_model\n",
        "from flask import Flask\n",
        "from flask import jsonify\n",
        "from flask import request\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route(\"/submit\", methods=['POST'])\n",
        "def sentiment_anaysis():\n",
        "  sample_text = request.values['text']\n",
        "  predictions = ''\n",
        "  return jsonify({'data':predictions})\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "6avhd5rVK8qW"
      },
      "source": [
        "#@markdown 啟用服務器\n",
        "import threading,sys\n",
        "class server_thread_wrapper(threading.Thread): \n",
        "  def __init__(self, *args, **keywords): \n",
        "    threading.Thread.__init__(self, *args, **keywords) \n",
        "    self.killed = False\n",
        "  def start(self): \n",
        "    self.__run_backup = self.run \n",
        "    self.run = self.__run       \n",
        "    threading.Thread.start(self) \n",
        "  \n",
        "  def __run(self): \n",
        "    sys.settrace(self.globaltrace) \n",
        "    self.__run_backup() \n",
        "    self.run = self.__run_backup \n",
        "  \n",
        "  def globaltrace(self, frame, event, arg): \n",
        "    if event == 'call': \n",
        "      return self.localtrace \n",
        "    else: \n",
        "      return None\n",
        "  \n",
        "  def localtrace(self, frame, event, arg): \n",
        "    if self.killed: \n",
        "      if event == 'line': \n",
        "        raise SystemExit() \n",
        "    return self.localtrace \n",
        "  \n",
        "  def kill(self): \n",
        "    self.killed = True\n",
        "\n",
        "def start_server():\n",
        "  server = server_thread_wrapper(target=app.run)\n",
        "  server.start()\n",
        "  return server\n",
        "\n",
        "def kill_server():\n",
        "  server.kill()\n",
        "  server.join()\n",
        "\n",
        "if server:\n",
        "  kill_server()\n",
        "## start the server\n",
        "server = start_server()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "sxUyrkZsdHPV",
        "cellView": "form",
        "outputId": "1233c5e8-8215-4d91-e582-631dbb40a9c1"
      },
      "source": [
        "#@markdown 檢視答案\n",
        "\n",
        "import requests\n",
        "payload = {'text': 'this is the worst movie I have ever had'}\n",
        "res = requests.post('http://127.0.0.1:5000/submit', data = payload)\n",
        "predictions = predictor.sample_predict(('this is the worst movie I have ever had'), pad=False)\n",
        "\n",
        "if predictions == res.json()['data']:\n",
        "  print('答案正確')\n",
        "else:\n",
        "  print('答案不正確歐，再想想還有哪邊要修改')\n",
        "  \n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [21/Mar/2021 23:47:43] \"\u001b[37mPOST /submit HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "''"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    }
  ]
}