{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jS0ZVOWBSVRy"
   },
   "source": [
    "## 練習題 3-4\n",
    "\n",
    "請協助調整以下API 程式碼，讓使用者可以調用該API 服務輸入資料，並透過該API 服務進行預測\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "id": "pyyeNEmzfN4E"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-06-21 08:50:29--  https://raw.githubusercontent.com/ywchiu/HPPY/main/model/sample_model.zip\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 6843295 (6.5M) [application/zip]\n",
      "Saving to: ‘sample_model.zip’\n",
      "\n",
      "sample_model.zip    100%[===================>]   6.53M  5.35MB/s    in 1.2s    \n",
      "\n",
      "2021-06-21 08:50:32 (5.35 MB/s) - ‘sample_model.zip’ saved [6843295/6843295]\n",
      "\n",
      "--2021-06-21 08:50:32--  https://raw.githubusercontent.com/ywchiu/HPPY/main/model/encoder.pickle\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 10190694 (9.7M) [application/octet-stream]\n",
      "Saving to: ‘encoder.pickle’\n",
      "\n",
      "encoder.pickle      100%[===================>]   9.72M  5.80MB/s    in 1.7s    \n",
      "\n",
      "2021-06-21 08:50:36 (5.80 MB/s) - ‘encoder.pickle’ saved [10190694/10190694]\n",
      "\n",
      "\u001b[34massets\u001b[m\u001b[m         saved_model.pb \u001b[34mvariables\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "#@markdown 解壓縮 sample_model\n",
    "\n",
    "! wget https://raw.githubusercontent.com/ywchiu/HPPY/main/model/sample_model.zip > /dev/null\n",
    "! wget https://raw.githubusercontent.com/ywchiu/HPPY/main/model/encoder.pickle > /dev/null\n",
    "! unzip sample_model.zip > /dev/null\n",
    "! ls sample_model/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ixfpSlsvcRYW"
   },
   "source": [
    "### 預測類別 Sentiment_prediciton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "10odm4i3a0Ll"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from  tensorflow.keras.models import load_model\n",
    "import pickle\n",
    "\n",
    "class Sentiment_prediciton(object):\n",
    "  def __init__(self, model_name, encoder_name):\n",
    "    self.model = load_model(model_name)\n",
    "    with open(encoder_name, 'rb') as handle:\n",
    "      self.encoder = pickle.load(handle)\n",
    "\n",
    "  def pad_to_size(self, vec, size):\n",
    "    zeros = [0] * (size - len(vec))\n",
    "    vec.extend(zeros)\n",
    "    return vec\n",
    "\n",
    "  def sample_predict(self, sample_pred_text, pad):\n",
    "    encoded_sample_pred_text = self.encoder.encode(sample_pred_text)\n",
    "\n",
    "    if pad:\n",
    "      encoded_sample_pred_text = pad_to_size(encoded_sample_pred_text, 64)\n",
    "    encoded_sample_pred_text = tf.cast(encoded_sample_pred_text, tf.float32)\n",
    "    predictions = self.model.predict(tf.expand_dims(encoded_sample_pred_text, 0))\n",
    "\n",
    "    return (predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b9KAGlUMZGxQ",
    "outputId": "b7511687-4498-41f2-eed8-2a8fbb4f92a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow_datasets'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-fb5c8c84c61b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSentiment_prediciton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sample_model'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'encoder.pickle'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'this is the worst movie I have ever had'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-c21630850822>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_name, encoder_name)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mpad_to_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow_datasets'"
     ]
    }
   ],
   "source": [
    "predictor = Sentiment_prediciton('sample_model', 'encoder.pickle')\n",
    "predictions = predictor.sample_predict(('this is the worst movie I have ever had'), pad=False)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GT8HrzTpgoDp"
   },
   "source": [
    "### 請完成以下程式碼，讓使用者得以用 Flask 提供正負向情緒判斷服務"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "SB_lGOOaf4gU"
   },
   "outputs": [],
   "source": [
    "from  tensorflow.keras.models import load_model\n",
    "from flask import Flask\n",
    "from flask import jsonify\n",
    "from flask import request\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route(\"/submit\", methods=['POST'])\n",
    "def sentiment_anaysis():\n",
    "  sample_text = request.values['text']\n",
    "  predictions = ''\n",
    "  return jsonify({'data':predictions})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "6avhd5rVK8qW"
   },
   "outputs": [],
   "source": [
    "#@markdown 啟用服務器\n",
    "import threading,sys\n",
    "class server_thread_wrapper(threading.Thread): \n",
    "  def __init__(self, *args, **keywords): \n",
    "    threading.Thread.__init__(self, *args, **keywords) \n",
    "    self.killed = False\n",
    "  def start(self): \n",
    "    self.__run_backup = self.run \n",
    "    self.run = self.__run       \n",
    "    threading.Thread.start(self) \n",
    "  \n",
    "  def __run(self): \n",
    "    sys.settrace(self.globaltrace) \n",
    "    self.__run_backup() \n",
    "    self.run = self.__run_backup \n",
    "  \n",
    "  def globaltrace(self, frame, event, arg): \n",
    "    if event == 'call': \n",
    "      return self.localtrace \n",
    "    else: \n",
    "      return None\n",
    "  \n",
    "  def localtrace(self, frame, event, arg): \n",
    "    if self.killed: \n",
    "      if event == 'line': \n",
    "        raise SystemExit() \n",
    "    return self.localtrace \n",
    "  \n",
    "  def kill(self): \n",
    "    self.killed = True\n",
    "\n",
    "def start_server():\n",
    "  server = server_thread_wrapper(target=app.run)\n",
    "  server.start()\n",
    "  return server\n",
    "\n",
    "def kill_server():\n",
    "  server.kill()\n",
    "  server.join()\n",
    "\n",
    "if server:\n",
    "  kill_server()\n",
    "## start the server\n",
    "server = start_server()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "sxUyrkZsdHPV",
    "outputId": "1233c5e8-8215-4d91-e582-631dbb40a9c1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [21/Mar/2021 23:47:43] \"\u001b[37mPOST /submit HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@markdown 檢視答案\n",
    "\n",
    "import requests\n",
    "payload = {'text': 'this is the worst movie I have ever had'}\n",
    "res = requests.post('http://127.0.0.1:5000/submit', data = payload)\n",
    "predictions = predictor.sample_predict(('this is the worst movie I have ever had'), pad=False)\n",
    "\n",
    "if predictions == res.json()['data']:\n",
    "  print('答案正確')\n",
    "else:\n",
    "  print('答案不正確歐，再想想還有哪邊要修改')\n",
    "  \n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "practice3-4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
